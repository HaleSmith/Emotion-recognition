{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(50, 50,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(output_dim=200,activation='relu'))\n",
    "model.add(Dense(output_dim=5,activation='sigmoid'))\n",
    "model.compile (optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = '/Users/abdulazizalreshidi/Desktop/sample_images'\n",
    "test_path = '/Users/abdulazizalreshidi/Desktop/sample_images_vali'\n",
    "IMG_BREDTH = 50\n",
    "IMG_HEIGHT = 50\n",
    "num_classes = 5\n",
    "\n",
    "nb_train_samples=203\n",
    "batch_size=5\n",
    "epochs=50\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory='/Users/abdulazizalreshidi/Desktop/sample_images',\n",
    "    target_size=(50, 50),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "valid_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory='/Users/abdulazizalreshidi/Desktop/sample_images_vali',\n",
    "    target_size=(50, 50),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "history=model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=70\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval =model.evaluate_generator(generator=valid_generator,steps=5)\n",
    "print(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict_generator(valid_generator,verbose=1,steps=5)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "print(predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot the training loss and accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = 70\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarize history for accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarize history for loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get training and test loss histories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create count of the number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count = range(1, len(training_loss) + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize loss history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get training and test accuracy histories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = history.history['acc']\n",
    "test_accuracy = history.history['val_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create count of the number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count = range(1, len(training_accuracy) + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize accuracy history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_count, training_accuracy, 'r--')\n",
    "plt.plot(epoch_count, test_accuracy, 'b-')\n",
    "plt.legend(['Training Accuracy', 'Test Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model with 91%.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evalate = model.evaluate_generator(generator=valid_generator,steps=1)\n",
    "print(Evalate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filenames = valid_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "predict = model.predict_generator(valid_generator,steps =\n",
    "                                   np.ceil(nb_samples/batch_size))\n",
    "\n",
    "predicted_class_indices=np.argmax(predict,axis=1)\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_image(img_path, show=False):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(50, 50))\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "\n",
    "    # load model\n",
    "    model = load_model(\"/Users/abdulazizalreshidi/PycharmProjects/emotional Recognition/model with 91%.h5\")\n",
    "\n",
    "    # image path\n",
    "    img_path = '/Users/abdulazizalreshidi/Desktop/sample_images_vali/anger_sad/S026_002_00000007.png'\n",
    "    # load a single image\n",
    "    new_image = load_image(img_path)\n",
    "\n",
    "    # check prediction\n",
    "    pred = model.predict(new_image)\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(new_image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dir='/Users/abdulazizalreshidi/Desktop/sample_images'\n",
    "validation_dir='/Users/abdulazizalreshidi/Desktop/sample_images_vali'\n",
    "\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary ()\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory=validation_dir,\n",
    "    target_size=(50, 50),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "# Get the filenames from the generator\n",
    "fnames = valid_generator.filenames\n",
    "\n",
    "# Get the ground truth from generator\n",
    "ground_truth = valid_generator.classes\n",
    "\n",
    "# Get the label to class mapping from the generator\n",
    "label2index = valid_generator.class_indices\n",
    "\n",
    "# Getting the mapping from class index to class label\n",
    "idx2label = dict ((v, k) for k, v in label2index.items ())\n",
    "\n",
    "# Get the predictions from the model using the generator\n",
    "predictions = model.predict_generator (valid_generator,\n",
    "                                       steps=valid_generator.samples / valid_generator.batch_size, verbose=1)\n",
    "predicted_classes = np.argmax (predictions, axis=1)\n",
    "\n",
    "errors = np.where (predicted_classes != ground_truth)[0]\n",
    "print (\"No of errors = {}/{}\".format (len (errors), valid_generator.samples))\n",
    "\n",
    "# Show the errors\n",
    "for i in range (len (errors)):\n",
    "    pred_class = np.argmax (predictions[errors[i]])\n",
    "    pred_label = idx2label[pred_class]\n",
    "\n",
    "    title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format (\n",
    "        fnames[errors[i]].split ('/')[0],\n",
    "        pred_label,\n",
    "        predictions[errors[i]][pred_class])\n",
    "\n",
    "    original = load_img ('{}/{}'.format (validation_dir, fnames[errors[i]]))\n",
    "    plt.figure (figsize=[7, 7])\n",
    "    plt.axis ('off')\n",
    "    plt.title (title)\n",
    "    plt.imshow (original)\n",
    "    plt.show ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_classes = valid_generator.classes\n",
    "class_labels = list(valid_generator.class_indices.keys())\n",
    "\n",
    "from sklearn import metrics\n",
    "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)\n",
    "accuracy = metrics.accuracy_score(true_classes, predicted_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "image = Image.open('/Users/abdulazizalreshidi/Desktop/sample_images_vali/anger_sad/S026_002_00000007.png')\n",
    "imgplot = plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import imageio\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1,\n",
    "       height_shift_range=0.1, zoom_range=0.1, # shear_range=0.15,\n",
    "       channel_shift_range=10., horizontal_flip=True, vertical_flip = True,\n",
    "       rescale = 0.2, fill_mode = 'wrap')\n",
    "\n",
    "image_path='/Users/abdulazizalreshidi/Desktop/sample_images_vali/anger_sad/S026_002_00000007.png'\n",
    "im=np.expand_dims(imageio.imread(image_path),0)\n",
    "plt.imshow(im[0])\n",
    "aug_iteration=gen.flow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "input_path = '/Users/abdulazizalreshidi/Desktop/sample_images_vali/anger_sad/S026_002_00000007.png'\n",
    "output_path = 'anger_sad{}.jpg'\n",
    "count = 10\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# load image to array\n",
    "image = img_to_array(load_img(input_path))\n",
    "\n",
    "# reshape to array rank 4\n",
    "image = image.reshape((1,) + image.shape)\n",
    "\n",
    "# let's create infinite flow of images\n",
    "images_flow = gen.flow(image, batch_size=1)\n",
    "for i, new_images in enumerate(images_flow):\n",
    "    # we access only first image because of batch_size=1\n",
    "    new_image = array_to_img(new_images[0], scale=True)\n",
    "    new_image.save(output_path.format(i + 1))\n",
    "    if i >= count:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
