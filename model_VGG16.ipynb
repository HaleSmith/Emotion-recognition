{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Human Facial Expression Recognition.\n",
    "#Explore and compare artificial intelligence and machine learning techniques to understand accuracy in classifying human facial expressions from images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading All library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Loading All Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"emotional data/\"\n",
    "file_anger_sad = path + \"anger_sad/\"\n",
    "file_casual = path + \"casual/\"\n",
    "file_joy_happy = path + \"joy_happy/\"\n",
    "file_sorrow = path + \"sorrow/\"\n",
    "file_surprise = path + \"surprise/\"\n",
    "from os import listdir\n",
    "import cv2\n",
    "\n",
    "def loadImages(path):\n",
    "    imagesList = listdir(path)\n",
    "    loadedImages = []\n",
    "    for image in imagesList:\n",
    "        img = cv2.imread(path + image)\n",
    "        img = cv2.resize(img, (50, 50))\n",
    "\n",
    "        loadedImages.append(img)\n",
    "\n",
    "    return loadedImages\n",
    "\n",
    "\n",
    "file_anger_sad=loadImages(file_anger_sad)\n",
    "file_casual = loadImages(file_casual)\n",
    "file_joy_happy = loadImages(file_joy_happy)\n",
    "file_sorrow = loadImages(file_sorrow)\n",
    "file_surprise = loadImages(file_surprise)\n",
    "\n",
    "\n",
    "total_X =[]\n",
    "label= []\n",
    "\n",
    "\n",
    "for i in range(len(file_anger_sad)):\n",
    "    total_X.append(file_anger_sad[i])\n",
    "    label.append(\"0\")\n",
    "\n",
    "for v in range(len(file_casual)):\n",
    "    total_X.append(file_casual[v])\n",
    "    label.append(\"1\")\n",
    "\n",
    "for n in range(len(file_joy_happy)):\n",
    "    total_X.append(file_joy_happy[n])\n",
    "    label.append(\"2\")\n",
    "\n",
    "for l in range (len (file_sorrow)):\n",
    "    total_X.append (file_sorrow[l])\n",
    "    label.append (\"3\")\n",
    "\n",
    "for a in range(len(file_surprise)):\n",
    "    total_X.append(file_surprise[a])\n",
    "    label.append(\"4\")\n",
    "\n",
    "\n",
    "total_X = np.asarray(total_X)\n",
    "label = np.asarray(label)\n",
    "\n",
    "\n",
    "label = to_categorical(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data into Training and Testing 90% for Training And 10% for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(total_X, label, test_size=0.1, random_state=66 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 model, with weights pre-trained on ImageNet.\n",
    "#The default input size for this model is 224x224.\n",
    "#This model can be built both with 'channels_first' data format (channels, height, width) or 'channels_last' data format (height, width, channels).\n",
    "Please Check keras webpage https://keras.io/applications/#vgg16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16 (weights='vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False,)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D () (x)\n",
    "\n",
    "\n",
    "\n",
    "x = Dense (100, activation='relu') (x)\n",
    "x = Dropout (0.15) (x)\n",
    "x = Dense (60, activation='relu') (x)\n",
    "x = Dense (30, activation='relu') (x)\n",
    "\n",
    "predictions = Dense(5, activation='softmax')(x)\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "model.compile (loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Fitting Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit (X_train, y_train, epochs=50, batch_size=50, verbose=1,validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting Model Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarize history for loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#ROC Curve\n",
    "yp_dum=pd.get_dummies(y_true)\n",
    "yt_dum=pd.get_dummies(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all ROC curves\n",
    "# Compute ROC curve and ROC area for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(class_names)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(yt_dum[i], yp_dum[i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure()\n",
    "colors=[\"blue\",\"darkviolet\",\"magenta\",\"orange\",\"gold\"]\n",
    "emote_list=np.unique(np.array(total_X))\n",
    "for i, color, emotion in zip(range(len(class_names)), colors, emote_list):\n",
    "    plt.plot(fpr[i], tpr[i], color=color,\n",
    "             label='ROC curve of class %s (area = %.2f)' %(emotion, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=np.unique(np.array(CM)) #Used for Confusion Matrix visual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "skplt.metrics.plot_confusion_matrix(y_true, pred, normalize=True)\n",
    "plt.show ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
